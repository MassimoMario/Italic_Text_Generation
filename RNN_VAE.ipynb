{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNVAE(nn.Module):\n",
    "    def __init__(self, embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size):\n",
    "        super(RNNVAE, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_matrix.shape[1]\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.sos_token = sos_token\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze = True)\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "        self.encoder = nn.RNN(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.decoder = nn.RNN(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)  \n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded_input = self.embedding(x)\n",
    "        embedded_input = self.layer_norm(embedded_input)\n",
    "\n",
    "        _, hn = self.encoder(embedded_input)\n",
    "\n",
    "        mu = self.fc_mu(hn)\n",
    "        logvar = self.fc_logvar(hn)\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "\n",
    "        z = self.fc_hidden(z)\n",
    "\n",
    "        # prepare sos_token for the decoder\n",
    "        sos_token = self.sos_token.repeat(x.size(0),1)\n",
    "        sos_token = self.embedding(sos_token)\n",
    "        sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "        decoder_input = torch.cat((sos_token, embedded_input), dim = 1)\n",
    "        decoder_input = decoder_input[:,:-1,:]\n",
    "\n",
    "        reconstructed_sequence, _ = self.decoder(decoder_input, z)\n",
    "        '''# reconstructing sequence through the decoder giving z as hidden state for each time step\n",
    "        reconstructed_sequence = []\n",
    "        for t in range(x.shape[1]):\n",
    "            outputs, _ = self.decoder(decoder_input[:,:t+1,:], z)\n",
    "            reconstructed_sequence.append(outputs[:,-1,:].unsqueeze(1))\n",
    "\n",
    "        # concatenating reconstructed words and push them into vocab_size dimensions\n",
    "        reconstructed_sequence = torch.cat(reconstructed_sequence, dim=1)'''\n",
    "        reconstructed_sequence = self.fc(reconstructed_sequence)\n",
    "        \n",
    "        return reconstructed_sequence, mu, logvar\n",
    "    \n",
    "\n",
    "\n",
    "    def reparametrization(self, mu, log_var):\n",
    "        ''' Reparametrization trick\n",
    "        \n",
    "        Inputs\n",
    "        -------\n",
    "        mu : torch tensor\n",
    "        log_var : torch tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mu + eps*std : torch tensor with the same shape as mu and log_var'''\n",
    "        \n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps*std\n",
    "\n",
    "\n",
    "    def reconstruction(self, x, sample_type = 'multinomial'):\n",
    "        ''' Reconstruction function for inference\n",
    "        Input\n",
    "        -------\n",
    "        x : torch tensor with shape [Batch_size, Sequence_length], input sequence\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        outputs : torch tensor with shape [Batch_size, Sequence_length, Embedding_dim], the reconstructed sentence'''\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # embedding input and GRU encoder pass\n",
    "            embedded_input = self.embedding(x)\n",
    "            embedded_input = self.layer_norm(embedded_input)\n",
    "            _, hn = self.encoder(embedded_input)\n",
    "            \n",
    "            # computing mu and log_var for style and content space\n",
    "            mu_s = self.fc_mu(hn)\n",
    "            logvar_s = self.fc_logvar(hn)\n",
    "\n",
    "            # reparametrization for style and content\n",
    "            z = self.reparametrization(mu_s, logvar_s)\n",
    "\n",
    "            # concatenating style and content space\n",
    "            z = self.fc_hidden(z)\n",
    "\n",
    "            # prepare sos_token for the decoder\n",
    "            sos_token = self.sos_token.repeat(x.size(0),1)\n",
    "            sos_token = self.embedding(sos_token)\n",
    "            sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "\n",
    "            # decoder pass where the input is the previous output\n",
    "            output = sos_token\n",
    "            for _ in range(x.shape[1]):\n",
    "                outputs, _ = self.decoder(output, z)\n",
    "                outputs = self.fc(outputs)\n",
    "                next_token = torch.argmax(F.softmax(outputs[:,-1,:], dim = -1), dim=-1)\n",
    "                #next_token = torch.multinomial(F.softmax(outputs[:,-1,:], dim = -1), 1)\n",
    "                next_token = self.embedding(next_token)\n",
    "                next_token = self.layer_norm(next_token)\n",
    "                output = torch.cat((output, next_token.unsqueeze(1)), dim=1)\n",
    "                #output = torch.cat((output, next_token), dim=1)\n",
    "        \n",
    "            \n",
    "        if sample_type == 'argmax':\n",
    "            output = torch.argmax(F.softmax(outputs.mean(0), dim = -1), dim = -1)\n",
    "            \n",
    "        elif sample_type == 'multinomial':\n",
    "            output = torch.multinomial(F.softmax(outputs.mean(0), dim = -1), 1)\n",
    "            \n",
    "\n",
    "        reconstructed_text = [self.idx2word[w.item()] for w in output]\n",
    "\n",
    "        return ' '.join(reconstructed_text)\n",
    "    \n",
    "\n",
    "    def sample(self, len_sample, sample_type = 'multinomial'):\n",
    "        hn = torch.randn((self.num_layers, 1, self.hidden_dim))\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            mu_s = self.fc_mu(hn)\n",
    "            logvar_s = self.fc_logvar(hn)\n",
    "\n",
    "            # reparametrization for style and content\n",
    "            z = self.reparametrization(mu_s, logvar_s)\n",
    "\n",
    "            # concatenating style and content space\n",
    "            z = self.fc_hidden(z)\n",
    "\n",
    "            # prepare sos_token for the decoder\n",
    "            sos_token = self.sos_token.repeat(1,1)\n",
    "            sos_token = self.embedding(sos_token)\n",
    "            sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "\n",
    "            # decoder pass where the input is the previous output\n",
    "            output = sos_token\n",
    "            for _ in range(len_sample):\n",
    "                outputs, _ = self.decoder(output, z)\n",
    "                outputs = self.fc(outputs)\n",
    "                next_token = torch.argmax(F.softmax(outputs[:,-1,:], dim = -1), dim=-1)\n",
    "                #next_token = torch.multinomial(F.softmax(outputs[:,-1,:], dim = -1), 1)\n",
    "                next_token = self.embedding(next_token)\n",
    "                next_token = self.layer_norm(next_token)\n",
    "                output = torch.cat((output, next_token.unsqueeze(1)), dim=1)\n",
    "                #output = torch.cat((output, next_token), dim=1)\n",
    "       \n",
    "        \n",
    "        if sample_type == 'argmax':\n",
    "            output = torch.argmax(F.softmax(outputs.mean(0), dim = -1), dim = -1)\n",
    "\n",
    "        elif sample_type == 'multinomial':\n",
    "            output = torch.multinomial(F.softmax(outputs.mean(0), dim = -1), 1)\n",
    "            \n",
    "\n",
    "        sampled_text = [self.idx2word[w.item()] for w in output]\n",
    "\n",
    "        return ' '.join(sampled_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUVAE(RNNVAE, nn.Module):\n",
    "    def __init__(self, embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size):\n",
    "        super(GRUVAE, self).__init__(embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size)\n",
    "        self.embedding_dim = embedding_matrix.shape[1]\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.sos_token = sos_token\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze = True)\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "        self.encoder = nn.GRU(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.decoder = nn.GRU(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)  \n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text(text, sequence_length):\n",
    "    ''' Function dividing text in order to feed the Word2vec model\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    text : text corpus from a file\n",
    "    sequence_length : int\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_text : 2D list of words with shape [text_length/sequence_length, sequence_length]'''\n",
    "\n",
    "    words = text.split()\n",
    "    grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),int(sequence_length/2))]  \n",
    "    output_text = [grouped_words[i].split() for i in range(len(grouped_words))]\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text_equal_seq_length(text, sequence_length):\n",
    "    ''' Function dividing text in order to feed the Word2vec model\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    text : text corpus from a file\n",
    "    sequence_length : int\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_text : 2D list of words with shape [text_length/sequence_length, sequence_length]'''\n",
    "\n",
    "    words = text.split()\n",
    "    grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),int(sequence_length/2))]  \n",
    "    output_text = [grouped_words[i].split() for i in range(len(grouped_words)) if len(grouped_words[i].split()) == sequence_length]\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_dataset(txt_file : str, sequence_length, embedding_dim, batch_size, training_fraction):\n",
    "    ''' Function creating dataset\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    file1 : str, name of the file containing the first corpus\n",
    "    file2 : str, name of the file containing the second corpus\n",
    "    file3 : str, name of the file containing the third corpus\n",
    "    sequence_length : int\n",
    "    embedding_dim : int, number of dimension for the embedded words using Word2vec model\n",
    "    batch_size : int\n",
    "    training_fraction : float, fraction of training data\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dataloader_train : istance of torch.utils.data.Dataloader, training data\n",
    "    dataloader_val : istance of torch.utils.data.Dataloader, validation data\n",
    "    embedding_dim : int\n",
    "    embedding_matrix : 2d torch tensor matrix from word2vec embedding\n",
    "    word2vec : trained Word2vec model\n",
    "    idx2word : dictionary from indices to words\n",
    "    word2idx : dictionart from words to indices\n",
    "    vocab_size : int, number of unique tokens\n",
    "    style0_test : torch tensor containing every test data belonging to first style\n",
    "    style1_test : torch tensor containing every test data belonging to second style\n",
    "    style3_test : torch tensor containing every test data belonging to third style'''\n",
    "\n",
    "    # reading the two corpus\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "\n",
    "    text = '<sos> ' + text\n",
    "    # divide the whole text to feed the Word2vec model\n",
    "    divided_text = divide_text(text, sequence_length)\n",
    "\n",
    "    # training the Word2vec model with the whole corpus\n",
    "    word2vec = Word2Vec(divided_text, vector_size = embedding_dim, window = sequence_length, min_count=1, workers=4, epochs = 30)\n",
    "    word2vec.train(divided_text, total_examples=word2vec.corpus_count, epochs=word2vec.epochs)\n",
    "\n",
    "    # Get the embedding dimension\n",
    "    embedding_dim = word2vec.wv.vector_size\n",
    "\n",
    "    # Prepare the embedding matrix\n",
    "    vocab_size = len(word2vec.wv)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    word2idx = {word: idx for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "\n",
    "    # creating the embedding matrix from the trained Word2vec model\n",
    "    for word, idx in word2idx.items():\n",
    "        embedding_matrix[idx] = word2vec.wv[word]\n",
    "\n",
    "    \n",
    "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    dataset = divide_text_equal_seq_length(text, sequence_length)\n",
    "    dataset = torch.LongTensor([[word2idx[char] for char in dataset[i]] for i in range(len(dataset))])\n",
    "\n",
    "\n",
    "    train_data = dataset[ : int(training_fraction * dataset.shape[0])]\n",
    "    val_data = dataset[int(training_fraction * dataset.shape[0]) : ]\n",
    "\n",
    "    dataset_train = TensorDataset(train_data)\n",
    "\n",
    "    # Create a training DataLoader with shuffling enabled\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "    dataset_val = TensorDataset(val_data)\n",
    "\n",
    "    # Create a validation DataLoader with shuffling enabled\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    \n",
    "    return dataloader_train, dataloader_val, embedding_dim, embedding_matrix, word2vec, idx2word, word2idx, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar, l_kl = 0.05, loss_fn = nn.CrossEntropyLoss()):\n",
    "    ''' Function computing loss function for classification\n",
    "    \n",
    "    Inputs\n",
    "    ---------\n",
    "    pred_labels : 3D torch tensor with predicted labels with shape [1, Batch size, 3]\n",
    "    labels : 2D torch tensor with ground truth labels with shape [Batch size, 3]\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    L : float, loss value '''\n",
    "\n",
    "    L = loss_fn(recon_x.reshape((recon_x.size(0)*recon_x.size(1),recon_x.size(2))), x.view(-1))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return L + l_kl * KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, num_epochs, lr = 4e-4, title = 'Training'):\n",
    "    ''' Training function\n",
    "    \n",
    "    Input\n",
    "    --------\n",
    "    model : istance of a CNNClassifier, RNNClassifier, GRUClassifier, LSTMClassifier or TClassifier\n",
    "    train_loader : istance of torch Dataloader with training data and labels\n",
    "    val_loader : istance of torch Dataloader with validation data and labels\n",
    "    num_epochs : int, number of epochs\n",
    "    lr : float, learning rate for Adam optimizer\n",
    "    title : str, Title of the matplot figure\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    train_losses : list with train loss values '''\n",
    "\n",
    "    params = list(model.parameters())\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(params, lr = lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    l_kl = 0.05\n",
    "\n",
    "    # For loop over epochs\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        train_loss = 0.0\n",
    "        average_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        average_val_loss = 0.0\n",
    "\n",
    "        # For loop for every batch\n",
    "        for  i, (inputs) in enumerate(train_loader):\n",
    "            inputs[0] = inputs[0].to(device)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            # forward pass through classifier\n",
    "            recon_x, mu, logvar = model(inputs[0])\n",
    "    \n",
    "            # comuting training loss\n",
    "            loss = vae_loss(recon_x.to(device),\n",
    "                            inputs[0].to(device),\n",
    "                            mu.to(device),\n",
    "                            logvar.to(device),\n",
    "                            l_kl)\n",
    "            \n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 5000 == 0:\n",
    "                print(f'Train Epoch: {epoch+1} [{i * len(inputs)}/{len(train_loader.dataset)} ({100. * i / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(inputs):.6f}')\n",
    "        \n",
    "        \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs) in enumerate(val_loader):\n",
    "                inputs[0] = inputs[0].to(device)\n",
    "    \n",
    "\n",
    "                # forward pass through classifier\n",
    "                recon_x, mu, logvar = model(inputs[0])\n",
    "                \n",
    "                \n",
    "                # comuting validation loss\n",
    "                val_loss_tot = vae_loss(recon_x.to(device),\n",
    "                                        inputs[0].to(device),\n",
    "                                        mu.to(device),\n",
    "                                        logvar.to(device),\n",
    "                                        l_kl)\n",
    "                \n",
    "                val_loss += val_loss_tot.item()\n",
    "\n",
    "\n",
    "                \n",
    "                if (i + 1) % 5000 == 0:\n",
    "                    print(f'Train Epoch: {epoch+1} [{i * len(inputs)}/{len(val_loader.dataset)} ({100. * i / len(val_loader):.0f}%)]\\tLoss: {val_loss_tot.item() / len(inputs):.6f}')\n",
    "            \n",
    "            \n",
    "        # Computing average training and validation loss\n",
    "        average_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(average_loss)\n",
    "\n",
    "        average_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(average_val_loss)\n",
    "        \n",
    "        # printing average training and validation losses\n",
    "        print(f'====> Epoch: {epoch+1} Average train loss: {average_loss:.4f}, Average val loss: {average_val_loss:.4f}')\n",
    "    \n",
    "\n",
    "    # Plotting training and validation curve at the end of the for loop \n",
    "    plt.plot(np.linspace(1,num_epochs,len(train_losses)), train_losses, c = 'darkcyan',label = 'train')\n",
    "    plt.plot(np.linspace(1,num_epochs,len(val_losses)), val_losses, c = 'orange',label = 'val')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25\n",
    "batch_size = 64\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "latent_dim = 136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of training samples:  7619\n",
      "total number of validation samples:  847\n",
      "vocab size:  12762\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, embedding_dim, embedding_matrix, word2vec, idx2word, word2idx, vocab_size = custom_dataset('divina_commedia.txt',\n",
    "                                                                                                                    sequence_length,\n",
    "                                                                                                                    embedding_dim,\n",
    "                                                                                                                    batch_size,\n",
    "                                                                                                                    0.9)\n",
    "\n",
    "print('total number of training samples: ', len(train_loader.dataset))\n",
    "print('total number of validation samples: ', len(val_loader.dataset))\n",
    "print('vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = torch.full((1,),word2idx['<sos>'])\n",
    "sos_token = sos_token.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = RNNVAE(embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, 1, sos_token, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters:  3671106\n"
     ]
    }
   ],
   "source": [
    "model_params = sum(p.numel() for p in vae.parameters() if p.requires_grad)\n",
    "\n",
    "print('Total parameters: ', model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:32<03:48, 32.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 1 Average train loss: 0.2279, Average val loss: 0.1331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [01:04<03:14, 32.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 2 Average train loss: 0.1078, Average val loss: 0.1104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [01:37<02:42, 32.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 3 Average train loss: 0.0982, Average val loss: 0.1080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [02:10<02:10, 32.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 4 Average train loss: 0.0941, Average val loss: 0.1065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [02:46<01:41, 33.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 5 Average train loss: 0.0907, Average val loss: 0.1060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [03:18<01:06, 33.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 6 Average train loss: 0.0876, Average val loss: 0.1053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [03:52<00:33, 33.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 7 Average train loss: 0.0847, Average val loss: 0.1049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [04:26<00:00, 33.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Epoch: 8 Average train loss: 0.0821, Average val loss: 0.1046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses = training(vae, train_loader, val_loader, 8, lr = 4e-4, title = 'RNN VAE Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: \n",
      " ch usurpa in terra il luogo mio il luogo mio il luogo mio che vaca ne la presenza del figliuol di dio fatt ha del\n",
      "\n",
      "Reconstructed sequence ARGMAX: \n",
      " e l altro che l mondo e l altro che l mondo e l altro che l mondo e l altro che l mondo e\n",
      "\n",
      "Reconstructed sequence MULTINOMIAL: \n",
      " giunti a muso di lor son santa facea e piange tutte in non frate cent quel cammino come ne duca vuoi questi altro reverenti l\n"
     ]
    }
   ],
   "source": [
    "for i ,(data) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        sentence = data[0][0]\n",
    "    else: \n",
    "        break\n",
    "\n",
    "input_sentence = [idx2word[sentence[i].item()] for i in range(sentence.shape[0])]\n",
    "\n",
    "sentence = sentence.view(1,sentence.shape[0])\n",
    "\n",
    "\n",
    "reconstructed_sequence = vae.reconstruction(sentence, 'argmax')\n",
    "\n",
    "reconstructed_sequence2 = vae.reconstruction(sentence)\n",
    "    \n",
    "\n",
    "\n",
    "'''indices = torch.argmax(reconstructed_sequence, dim=-1).squeeze(0)\n",
    "indices2 = torch.multinomial(F.softmax(reconstructed_sequence.squeeze(0),dim=-1), 1)\n",
    "\n",
    "\n",
    "reconstructed_sequence = []\n",
    "for i in range(sentence.shape[1]):\n",
    "    reconstructed_sequence.append(idx2word[indices[i].item()])'''\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input sequence: \\n\", ' '.join(input_sentence))\n",
    "print(\"\\nReconstructed sequence ARGMAX: \\n\", reconstructed_sequence)\n",
    "print(\"\\nReconstructed sequence MULTINOMIAL: \\n\", reconstructed_sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence: \n",
      " quella ch io notai di più carezza vid io uscire un foco sì felice che nullo vi lasciò di più chiarezza e tre fiate intorno\n",
      "\n",
      "Reconstructed sequence 2: \n",
      " sobranza era a soli lezzo centro bella a io lui ci sol ond quant quel l gomita speran fu dolore briareo titone le rilevarsi molti\n"
     ]
    }
   ],
   "source": [
    "for i ,(data) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        sentence = data[0][0]\n",
    "    else: \n",
    "        break\n",
    "\n",
    "input_sentence = [idx2word[sentence[i].item()] for i in range(sentence.shape[0])]\n",
    "\n",
    "sentence = sentence.view(1,sentence.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_sequence, _, _ = vae.forward(sentence)\n",
    "    \n",
    "\n",
    "\n",
    "indices = torch.argmax(reconstructed_sequence, dim=-1).squeeze(0)\n",
    "indices2 = torch.multinomial(F.softmax(reconstructed_sequence.squeeze(0),dim=-1), 1)\n",
    "\n",
    "\n",
    "reconstructed_sequence = []\n",
    "for i in range(sentence.shape[1]):\n",
    "    reconstructed_sequence.append(idx2word[indices2[i].item()])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input sequence: \\n\", ' '.join(input_sentence))\n",
    "print(\"\\nReconstructed sequence 2: \\n\", ' '.join(reconstructed_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atteggiata già è si nfino uso benaco chi opere nel tardi uccel presente zenone ciel agnel sotto anima esperto ndarno'"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
