{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNVAE(nn.Module):\n",
    "    def __init__(self, embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size):\n",
    "        super(RNNVAE, self).__init__()\n",
    "\n",
    "        self.embedding_dim = embedding_matrix.shape[1]\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.sos_token = sos_token\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze = True)\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "        self.encoder = nn.RNN(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.decoder = nn.RNN(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)  \n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded_input = self.embedding(x)\n",
    "        embedded_input = self.layer_norm(embedded_input)\n",
    "\n",
    "        _, hn = self.encoder(embedded_input)\n",
    "\n",
    "        mu = self.fc_mu(hn)\n",
    "        logvar = self.fc_logvar(hn)\n",
    "        z = self.reparametrization(mu, logvar)\n",
    "\n",
    "        z = self.fc_hidden(z)\n",
    "\n",
    "        # prepare sos_token for the decoder\n",
    "        sos_token = self.sos_token.repeat(x.size(0),1)\n",
    "        sos_token = self.embedding(sos_token)\n",
    "        sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "        decoder_input = torch.cat((sos_token, embedded_input), dim = 1)\n",
    "        decoder_input = decoder_input[:,:-1,:]\n",
    "\n",
    "        reconstructed_sequence, _ = self.decoder(decoder_input, z)\n",
    "        '''# reconstructing sequence through the decoder giving z as hidden state for each time step\n",
    "        reconstructed_sequence = []\n",
    "        for t in range(x.shape[1]):\n",
    "            outputs, _ = self.decoder(decoder_input[:,:t+1,:], z)\n",
    "            reconstructed_sequence.append(outputs[:,-1,:].unsqueeze(1))\n",
    "\n",
    "        # concatenating reconstructed words and push them into vocab_size dimensions\n",
    "        reconstructed_sequence = torch.cat(reconstructed_sequence, dim=1)'''\n",
    "        reconstructed_sequence = self.fc(reconstructed_sequence)\n",
    "        \n",
    "        return reconstructed_sequence, mu, logvar\n",
    "    \n",
    "\n",
    "\n",
    "    def reparametrization(self, mu, log_var):\n",
    "        ''' Reparametrization trick\n",
    "        \n",
    "        Inputs\n",
    "        -------\n",
    "        mu : torch tensor\n",
    "        log_var : torch tensor\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        mu + eps*std : torch tensor with the same shape as mu and log_var'''\n",
    "        \n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + eps*std\n",
    "\n",
    "\n",
    "    def reconstruction(self, x, sample_type = 'multinomial'):\n",
    "        ''' Reconstruction function for inference\n",
    "        Input\n",
    "        -------\n",
    "        x : torch tensor with shape [Batch_size, Sequence_length], input sequence\n",
    "            \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        outputs : torch tensor with shape [Batch_size, Sequence_length, Embedding_dim], the reconstructed sentence'''\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # embedding input and GRU encoder pass\n",
    "            embedded_input = self.embedding(x)\n",
    "            embedded_input = self.layer_norm(embedded_input)\n",
    "            _, hn = self.encoder(embedded_input)\n",
    "            \n",
    "            # computing mu and log_var for style and content space\n",
    "            mu_s = self.fc_mu(hn)\n",
    "            logvar_s = self.fc_logvar(hn)\n",
    "\n",
    "            # reparametrization for style and content\n",
    "            z = self.reparametrization(mu_s, logvar_s)\n",
    "\n",
    "            # concatenating style and content space\n",
    "            z = self.fc_hidden(z)\n",
    "\n",
    "            # prepare sos_token for the decoder\n",
    "            sos_token = self.sos_token.repeat(x.size(0),1)\n",
    "            sos_token = self.embedding(sos_token)\n",
    "            sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "\n",
    "            # decoder pass where the input is the previous output\n",
    "            output = sos_token\n",
    "            for _ in range(x.shape[1]):\n",
    "                outputs, _ = self.decoder(output, z)\n",
    "                outputs = self.fc(outputs)\n",
    "                next_token = torch.argmax(F.softmax(outputs[:,-1,:], dim = -1), dim=-1)\n",
    "                #next_token = torch.multinomial(F.softmax(outputs[:,-1,:], dim = -1), 1)\n",
    "                next_token = self.embedding(next_token)\n",
    "                next_token = self.layer_norm(next_token)\n",
    "                output = torch.cat((output, next_token.unsqueeze(1)), dim=1)\n",
    "                #output = torch.cat((output, next_token), dim=1)\n",
    "        \n",
    "            \n",
    "        if sample_type == 'argmax':\n",
    "            output = torch.argmax(F.softmax(outputs.mean(0), dim = -1), dim = -1)\n",
    "            \n",
    "        elif sample_type == 'multinomial':\n",
    "            output = torch.multinomial(F.softmax(outputs.mean(0), dim = -1), 1)\n",
    "            \n",
    "\n",
    "        reconstructed_text = [self.idx2word[w.item()] for w in output]\n",
    "\n",
    "        return ' '.join(reconstructed_text)\n",
    "    \n",
    "\n",
    "    def sample(self, len_sample = 25, sample_type = 'multinomial'):\n",
    "        z = torch.randn((self.num_layers, 1, self.latent_dim))\n",
    "\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = self.fc_hidden(z)\n",
    "\n",
    "            # prepare sos_token for the decoder\n",
    "            sos_token = self.sos_token.repeat(1,1)\n",
    "            sos_token = self.embedding(sos_token)\n",
    "            sos_token = self.layer_norm(sos_token)\n",
    "\n",
    "\n",
    "            # decoder pass where the input is the previous output\n",
    "            output = sos_token\n",
    "            for _ in range(len_sample):\n",
    "                outputs, _ = self.decoder(output, z)\n",
    "                outputs = self.fc(outputs)\n",
    "                next_token = torch.argmax(F.softmax(outputs[:,-1,:], dim = -1), dim=-1)\n",
    "                #next_token = torch.multinomial(F.softmax(outputs[:,-1,:], dim = -1), 1)\n",
    "                next_token = self.embedding(next_token)\n",
    "                next_token = self.layer_norm(next_token)\n",
    "                output = torch.cat((output, next_token.unsqueeze(1)), dim=1)\n",
    "                #output = torch.cat((output, next_token), dim=1)\n",
    "       \n",
    "        \n",
    "        if sample_type == 'argmax':\n",
    "            output = torch.argmax(F.softmax(outputs.mean(0), dim = -1), dim = -1)\n",
    "\n",
    "        elif sample_type == 'multinomial':\n",
    "            output = torch.multinomial(F.softmax(outputs.mean(0), dim = -1), 1)\n",
    "            \n",
    "\n",
    "        sampled_text = [self.idx2word[w.item()] for w in output]\n",
    "\n",
    "        return ' '.join(sampled_text)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def number_parameters(self):\n",
    "\n",
    "        model_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "        print('Total number of model parameters: ', model_params)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUVAE(RNNVAE, nn.Module):\n",
    "    def __init__(self, embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size):\n",
    "        super().__init__(embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, num_layers, sos_token, vocab_size)\n",
    "\n",
    "        self.embedding_dim = embedding_matrix.shape[1]\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "        self.sos_token = sos_token\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze = True)\n",
    "        self.layer_norm = nn.LayerNorm(self.embedding_dim)\n",
    "\n",
    "        self.encoder = nn.GRU(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "        self.decoder = nn.GRU(self.embedding_dim, hidden_dim, num_layers, batch_first = True)\n",
    "\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)  \n",
    "        self.fc_logvar = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_hidden = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text(text, sequence_length):\n",
    "    ''' Function dividing text in order to feed the Word2vec model\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    text : text corpus from a file\n",
    "    sequence_length : int\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_text : 2D list of words with shape [text_length/sequence_length, sequence_length]'''\n",
    "\n",
    "    words = text.split()\n",
    "    grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),int(sequence_length/2))]  \n",
    "    output_text = [grouped_words[i].split() for i in range(len(grouped_words))]\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_text_equal_seq_length(text, sequence_length):\n",
    "    ''' Function dividing text in order to feed the Word2vec model\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    text : text corpus from a file\n",
    "    sequence_length : int\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    output_text : 2D list of words with shape [text_length/sequence_length, sequence_length]'''\n",
    "\n",
    "    words = text.split()\n",
    "    grouped_words = [' '.join(words[i:i+sequence_length]) for i in range(0,len(words),int(sequence_length/2))]  \n",
    "    output_text = [grouped_words[i].split() for i in range(len(grouped_words)) if len(grouped_words[i].split()) == sequence_length]\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_dataset(txt_file : str, sequence_length : int, embedding_dim : int, batch_size : int, training_fraction : float):\n",
    "    ''' Function creating dataset\n",
    "    \n",
    "    Inputs\n",
    "    ----------\n",
    "    file1 : str, name of the file containing the text corpus\n",
    "    sequence_length : int\n",
    "    embedding_dim : int, number of dimension for the embedded words using Word2vec model\n",
    "    batch_size : int\n",
    "    training_fraction : float, fraction of training data\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    dataloader_train : istance of torch.utils.data.Dataloader, training data\n",
    "    dataloader_val : istance of torch.utils.data.Dataloader, validation data\n",
    "    embedding_dim : int\n",
    "    embedding_matrix : 2d torch tensor matrix from word2vec embedding\n",
    "    word2vec : trained Word2vec model\n",
    "    idx2word : dictionary from indices to words\n",
    "    word2idx : dictionart from words to indices\n",
    "    vocab_size : int, number of unique tokens\n",
    "    style0_test : torch tensor containing every test data belonging to first style\n",
    "    style1_test : torch tensor containing every test data belonging to second style\n",
    "    style3_test : torch tensor containing every test data belonging to third style'''\n",
    "\n",
    "    # reading the two corpus\n",
    "    with open(txt_file, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "\n",
    "    text = '<sos> ' + text\n",
    "    # divide the whole text to feed the Word2vec model\n",
    "    divided_text = divide_text(text, sequence_length)\n",
    "\n",
    "    # training the Word2vec model with the whole corpus\n",
    "    word2vec = Word2Vec(divided_text, vector_size = embedding_dim, window = sequence_length, min_count=1, workers=4, epochs = 30)\n",
    "    word2vec.train(divided_text, total_examples=word2vec.corpus_count, epochs=word2vec.epochs)\n",
    "\n",
    "    # Get the embedding dimension\n",
    "    embedding_dim = word2vec.wv.vector_size\n",
    "\n",
    "    # Prepare the embedding matrix\n",
    "    vocab_size = len(word2vec.wv)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    word2idx = {word: idx for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "    idx2word = {idx: word for idx, word in enumerate(word2vec.wv.index_to_key)}\n",
    "\n",
    "    # creating the embedding matrix from the trained Word2vec model\n",
    "    for word, idx in word2idx.items():\n",
    "        embedding_matrix[idx] = word2vec.wv[word]\n",
    "\n",
    "    \n",
    "    embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
    "\n",
    "\n",
    "    \n",
    "    dataset = divide_text_equal_seq_length(text, sequence_length)\n",
    "    dataset = torch.LongTensor([[word2idx[char] for char in dataset[i]] for i in range(len(dataset))])\n",
    "\n",
    "\n",
    "    train_data = dataset[ : int(training_fraction * dataset.shape[0])]\n",
    "    val_data = dataset[int(training_fraction * dataset.shape[0]) : ]\n",
    "\n",
    "    dataset_train = TensorDataset(train_data)\n",
    "\n",
    "    # Create a training DataLoader with shuffling enabled\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "\n",
    "    dataset_val = TensorDataset(val_data)\n",
    "\n",
    "    # Create a validation DataLoader with shuffling enabled\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size = batch_size, shuffle = True)\n",
    "    \n",
    "    \n",
    "    return dataloader_train, dataloader_val, embedding_dim, embedding_matrix, word2vec, idx2word, word2idx, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, logvar, l_kl = 0.05, loss_fn = nn.CrossEntropyLoss()):\n",
    "    ''' Function computing loss function for classification\n",
    "    \n",
    "    Inputs\n",
    "    ---------\n",
    "    pred_labels : 3D torch tensor with predicted labels with shape [1, Batch size, 3]\n",
    "    labels : 2D torch tensor with ground truth labels with shape [Batch size, 3]\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    L : float, loss value '''\n",
    "\n",
    "    L = loss_fn(recon_x.reshape((recon_x.size(0)*recon_x.size(1),recon_x.size(2))), x.view(-1))\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return L + l_kl * KLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid controlling l_kl:\n",
    "* k = 0.183, t0 = 20\n",
    "* k = 0.11, t0 = 30\n",
    "\n",
    "\n",
    "k = - ln(32.33333)/(1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, k = 0.183, t0 = 20):\n",
    "    \n",
    "    return 1/(1 + np.exp(-k*(x-t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_loader, val_loader, num_epochs, lr = 4e-4, title = 'Training'):\n",
    "    ''' Training function\n",
    "    \n",
    "    Input\n",
    "    --------\n",
    "    model : istance of a CNNClassifier, RNNClassifier, GRUClassifier, LSTMClassifier or TClassifier\n",
    "    train_loader : istance of torch Dataloader with training data and labels\n",
    "    val_loader : istance of torch Dataloader with validation data and labels\n",
    "    num_epochs : int, number of epochs\n",
    "    lr : float, learning rate for Adam optimizer\n",
    "    title : str, Title of the matplot figure\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    train_losses : list with train loss values '''\n",
    "\n",
    "    params = list(model.parameters())\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(params, lr = lr)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    #l_kl = 0.05\n",
    "\n",
    "    # For loop over epochs\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        l_kl = sigmoid(epoch + 1)\n",
    "        train_loss = 0.0\n",
    "        average_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        average_val_loss = 0.0\n",
    "\n",
    "        # For loop for every batch\n",
    "        for  i, (inputs) in enumerate(train_loader):\n",
    "            inputs[0] = inputs[0].to(device)\n",
    "            \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "\n",
    "            # forward pass through classifier\n",
    "            recon_x, mu, logvar = model(inputs[0])\n",
    "    \n",
    "            # comuting training loss\n",
    "            loss = vae_loss(recon_x.to(device),\n",
    "                            inputs[0].to(device),\n",
    "                            mu.to(device),\n",
    "                            logvar.to(device),\n",
    "                            l_kl)\n",
    "            \n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i + 1) % 5000 == 0:\n",
    "                print(f'Train Epoch: {epoch+1} [{i * len(inputs)}/{len(train_loader.dataset)} ({100. * i / len(train_loader):.0f}%)]\\tLoss: {loss.item() / len(inputs):.6f}')\n",
    "        \n",
    "        \n",
    "        # Validation\n",
    "        with torch.no_grad():\n",
    "            for i, (inputs) in enumerate(val_loader):\n",
    "                inputs[0] = inputs[0].to(device)\n",
    "    \n",
    "\n",
    "                # forward pass through classifier\n",
    "                recon_x, mu, logvar = model(inputs[0])\n",
    "                \n",
    "                \n",
    "                # comuting validation loss\n",
    "                val_loss_tot = vae_loss(recon_x.to(device),\n",
    "                                        inputs[0].to(device),\n",
    "                                        mu.to(device),\n",
    "                                        logvar.to(device),\n",
    "                                        l_kl)\n",
    "                \n",
    "                val_loss += val_loss_tot.item()\n",
    "\n",
    "\n",
    "                \n",
    "                if (i + 1) % 5000 == 0:\n",
    "                    print(f'Train Epoch: {epoch+1} [{i * len(inputs)}/{len(val_loader.dataset)} ({100. * i / len(val_loader):.0f}%)]\\tLoss: {val_loss_tot.item() / len(inputs):.6f}')\n",
    "            \n",
    "            \n",
    "        # Computing average training and validation loss\n",
    "        average_loss = train_loss / len(train_loader.dataset)\n",
    "        train_losses.append(average_loss)\n",
    "\n",
    "        average_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(average_val_loss)\n",
    "        \n",
    "        # printing average training and validation losses\n",
    "        print(f'====> Epoch: {epoch+1} Average train loss: {average_loss:.4f}, Average val loss: {average_val_loss:.4f}')\n",
    "    \n",
    "\n",
    "    # Plotting training and validation curve at the end of the for loop \n",
    "    plt.plot(np.linspace(1,num_epochs,len(train_losses)), train_losses, c = 'darkcyan',label = 'train')\n",
    "    plt.plot(np.linspace(1,num_epochs,len(val_losses)), val_losses, c = 'orange',label = 'val')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 25\n",
    "batch_size = 64\n",
    "embedding_dim = 300\n",
    "hidden_dim = 256\n",
    "latent_dim = 136"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, embedding_dim, embedding_matrix, word2vec, idx2word, word2idx, vocab_size = custom_dataset('divina_commedia.txt',\n",
    "                                                                                                                    sequence_length,\n",
    "                                                                                                                    embedding_dim,\n",
    "                                                                                                                    batch_size,\n",
    "                                                                                                                    0.9)\n",
    "\n",
    "print('total number of training samples: ', len(train_loader.dataset))\n",
    "print('total number of validation samples: ', len(val_loader.dataset))\n",
    "print('vocab size: ', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = torch.full((1,),word2idx['<sos>'])\n",
    "sos_token = sos_token.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = RNNVAE(embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, 3, sos_token, vocab_size)\n",
    "vae.number_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = GRUVAE(embedding_matrix, word2idx, idx2word, hidden_dim, latent_dim, 3, sos_token, vocab_size)\n",
    "vae.number_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = training(vae, train_loader, val_loader, 8, lr = 4e-4, title = 'RNN VAE Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,(data) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        sentence = data[0][0]\n",
    "    else: \n",
    "        break\n",
    "\n",
    "input_sentence = [idx2word[sentence[i].item()] for i in range(sentence.shape[0])]\n",
    "\n",
    "sentence = sentence.view(1,sentence.shape[0])\n",
    "\n",
    "\n",
    "reconstructed_sequence = vae.reconstruction(sentence, 'argmax')\n",
    "\n",
    "reconstructed_sequence2 = vae.reconstruction(sentence)\n",
    "    \n",
    "\n",
    "\n",
    "'''indices = torch.argmax(reconstructed_sequence, dim=-1).squeeze(0)\n",
    "indices2 = torch.multinomial(F.softmax(reconstructed_sequence.squeeze(0),dim=-1), 1)\n",
    "\n",
    "\n",
    "reconstructed_sequence = []\n",
    "for i in range(sentence.shape[1]):\n",
    "    reconstructed_sequence.append(idx2word[indices[i].item()])'''\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input sequence: \\n\", ' '.join(input_sentence))\n",
    "print(\"\\nReconstructed sequence ARGMAX: \\n\", reconstructed_sequence)\n",
    "print(\"\\nReconstructed sequence MULTINOMIAL: \\n\", reconstructed_sequence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,(data) in enumerate(val_loader):\n",
    "    if i == 0:\n",
    "        sentence = data[0][0]\n",
    "    else: \n",
    "        break\n",
    "\n",
    "input_sentence = [idx2word[sentence[i].item()] for i in range(sentence.shape[0])]\n",
    "\n",
    "sentence = sentence.view(1,sentence.shape[0])\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_sequence, _, _ = vae.forward(sentence)\n",
    "    \n",
    "\n",
    "\n",
    "indices = torch.argmax(reconstructed_sequence, dim=-1).squeeze(0)\n",
    "indices2 = torch.multinomial(F.softmax(reconstructed_sequence.squeeze(0),dim=-1), 1)\n",
    "\n",
    "\n",
    "reconstructed_sequence = []\n",
    "for i in range(sentence.shape[1]):\n",
    "    reconstructed_sequence.append(idx2word[indices2[i].item()])\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input sequence: \\n\", ' '.join(input_sentence))\n",
    "print(\"\\nReconstructed sequence 2: \\n\", ' '.join(reconstructed_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
